{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import requests\n",
    "import skimage.io\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 0: Set up\n",
    "\n",
    "Before we proceed we need to setup and launch a few things.\n",
    "\n",
    "## DVC\n",
    "We assume that the data version control is set up and we'll pull the data from the remote"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! git checkout master\n",
    "! dvc pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## MLFlow\n",
    "MLFlow is used for experiment tracking. We just use local server for tracking, but in a real world scenario I would connect to a remote one, shared by the team. Run the command below in your shell to start the server\n",
    "```\n",
    "mlflow server\n",
    "```\n",
    "\n",
    "## Model training server\n",
    "The server has been written for this exersice, that will perform model training, evaluation as well as data relabeling procedures. Assuming the environment is already set up, run this command in your shell to start it.\n",
    "```\n",
    "python server/server.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Part 1: Train and evaluate the initial model\n",
    "We first call the server to train a model using the initial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "requests.post(\"http://localhost:8000/train_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Let's check what dataset versions were tracked by MLFlow for this model training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "last_run = mlflow.search_runs().iloc[0]\n",
    "print(\"Train dataset: \", last_run[\"params.train_git_revisions\"], last_run[\"params.train_committed_datetime\"])\n",
    "print(\"Test dataset: \", last_run[\"params.test_git_revisions\"], last_run[\"params.test_committed_datetime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The server has successfully finished training a model; the model artifact is now available on the filesystem at `models/classifier.keras` as well as in the MLFlow registry.\n",
    "\n",
    "You can visit [the MLFlow experiment dashboard](http://127.0.0.1:5000/#/experiments) to view the experiment results (i.e training, validation and testing performance, artifacts, etc.). Alternatively, we can query the model training server directly to do model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"http://localhost:8000/evaluate_model\")\n",
    "display(response)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Test accuracy of ~85%, the model is not too great at identifying threats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Part 2: Relabeling\n",
    "\n",
    "We were hinted at that some the images marked as enemies (class ID 0), are indeed not enemies. For example, we can see an impostor dog's picture under `data/train/0/1b2c58d79150a6b863b2c8e8619c98ca.jpg`\n",
    "\n",
    "![](data/train/0/1b2c58d79150a6b863b2c8e8619c98ca.jpg)\n",
    "\n",
    "We want to identify more of these and relabel them to Class ID 1. Looking through the whole training set would require time. But we can simplify our job by performing similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The process is still requires manual intervention (to confirm that the found images are indeed impostor's). The process is iterative, some cells need to be run multiple times:\n",
    "1. Run the `Setup Relabeling` cell ones\n",
    "2. Run the `Take Next Seed` cell ones\n",
    "3. Run the `Query Similar Images` cell, and check that the images are indeed Arnie\n",
    "4. Modify `MARKED_TO_RELABEL` list according to which images you want to relabel, and run the `Relabel Request` cell\n",
    "5. Repeat from 2, until done.\n",
    "\n",
    "PUBLIC NOTE: This process is a bit clunky in the notebook, and I would probably do it in some simple web UI or CLI tool in the real world.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Setup Relabeling\n",
    "seed_image_id = \"1b2c58d79150a6b863b2c8e8619c98ca\"\n",
    "images_relabeled = 0\n",
    "search_iterations = 0\n",
    "seed_image_queue = [seed_image_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Take Next Seed\n",
    "if len(seed_image_queue) > 0:\n",
    "    seed_image_id = seed_image_queue.pop(0)\n",
    "    display(seed_image_id)\n",
    "else:\n",
    "    display(\"No seed images left.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Query Similar Images\n",
    "response = requests.get(f\"http://localhost:8000/similar_images?img_id={seed_image_id}&class_id=0&n=3\")\n",
    "similar_images = response.json()\n",
    "for i, image in enumerate(similar_images):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    skimage.io.imshow(f\"data/train/0/{image['id']}.jpg\")\n",
    "    plt.title(image[\"id\"])\n",
    "plt.show()\n",
    "search_iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Relabel Request\n",
    "# IMPORTANT: modify MARKED_TO_RELABEL according to what you see above before running\n",
    "MARKED_TO_RELABEL = [\n",
    "    False,\n",
    "    False,\n",
    "    True\n",
    "]\n",
    "\n",
    "for i in range(3):\n",
    "    if MARKED_TO_RELABEL[i]:\n",
    "        image = similar_images[i]\n",
    "        display(f\"Relabel {image['id']} to Class ID 1\")\n",
    "        display(requests.post(\"http://localhost:8000/relabel\", json={\"img_id\": image['id'], \"class_id\": 1}))\n",
    "        seed_image_queue += [image[\"id\"]]\n",
    "        images_relabeled += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total search iterations\", search_iterations)\n",
    "print(\"Total images relabeled\", images_relabeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now that the Arnies are relabeled, we can version the resulting training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "! dvc add data/train\n",
    "! git add data/train.dvc\n",
    "! git commit -m \"Version training dataset after relabeling the impostor dog\"\n",
    "! git tag data-v2-clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Part 3: Did we do better?\n",
    "\n",
    "Now let's retrain the model and see if the performance is any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "display(requests.post(\"http://localhost:8000/train_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Let's confirm that the model training run has indeed used the updated versions of the data (only the training dataset should show an update in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "last_run = mlflow.search_runs().iloc[0]\n",
    "print(\"Train dataset: \", last_run[\"params.train_git_revisions\"], last_run[\"params.train_committed_datetime\"])\n",
    "print(\"Test dataset: \", last_run[\"params.test_git_revisions\"], last_run[\"params.test_committed_datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"http://localhost:8000/evaluate_model\")\n",
    "display(response)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The performance has improved greatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
